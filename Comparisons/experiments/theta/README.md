# THETA: 和大模型对比效果

实验比我想象中的要难, 进展缓慢. 解释一下. 

## 目标

我们想要证明自己 图卷积网络+嵌入向量 的方法, 要比直接使用大模型要好. 

下游任务重会用到仓库,PR和开发者的向量 (相似开发者, PR审阅人, ContributionRepo, RepoMaintainer). 如果可以用LLM生成这三部分的向量, 就可以做所有的下游任务; 如果只有开发者的, 就可以做其中一个. 

我们先假设只获取开发者嵌入. 原本的工作中, 我们是获取了另外三种实体的嵌入, 再通过图生成开发者嵌入; 但由于要证明图卷积的必要性, 对比实验中不会用到图卷积. 因此我们参考 Dev2Vec 中的方法, 将与开发者关联的实体的嵌入分别平均, 然后拼接起来作为开发者的嵌入. 

> 具体地: 我们先找到和开发者关联的所有Issue. 将所有Issue的嵌入平均后得到开发者嵌入的第一部分; 用同样的方法得到开发者嵌入的第二第三部分(分别从PR和Repository中获得.), 将这三部分拼接起来, 作为开发者的嵌入. 

然后, 我们使用此嵌入做下游任务. 


## 任务,现状和原因

1. 怎么用LLM/实体的嵌入如何获得?  
   已经搞定的是: 输入文本, 输出嵌入. llama3也具有理解代码的能力. 而原本的代码中, 嵌入的生成包括三部分: NL, 代码(CL)和离散数据. 具体地: 
   - Issue: 只有NL. 代码已写好, 等待GPU资源; 
   - PR:    NL ++ CL; 
   - Repo:  NL ++ CL ++ T ++ L. 后两个都是离散数据;
   (详见毕业论文P15, 3.3 初始技术特征挖掘)

   我们只要将其中 NL 和 CL 的部分, 从 BERT/CodeBERT 改成 llama 就行了. 但这并不好改. 有两个思路实现这部分: 
   1. 在原代码的基础上修改. 原本代码与生成向量的相关部分在: `/NodeFeatureInitializer` 中. 关于 NL 和 CL 的生成在 `embedder_{code,text}` 两个文件中. 按理说我们直接修改这两个文件就可以了. 但: 
        1. 原数据可能会被不小心抹除掉; 
        2. 不知道数据流动的方向, 也就不知道应该按照什么顺序执行代码; 
        3. 不知道生成数据要如何使用. 
   2. 自己重新写. 但这就需要了解原来代码的所有细节. 这很难. 

   我更倾向于第一种, 但还在考虑怎么避免数据抹除的问题, 以及了解生成的数据是怎么用的. 对我而言, 这部分代码之前从来没有看过, 对我而言是比较新的工作. 


2. 哪些仓库是和开发者"关联"的?  
   在平均开发者关联的实体时用到. PR和Issue只有一种关系, 无所谓.  
   开发者和开发者和仓库之间有star,贡献,watch三种关系. naive的想法是直接都用上; 但在某个下游任务选择scope中用到了一种筛选和开发者相关仓库的方法, 做到这一步时找到它并应用. 


3. 能否用其他三部分的嵌入?   
   我感觉可以. 但这是扩展工作. 主线任务若能做好, 那这个也没问题. 先放一放. 

4. 嵌入维度过高:  
   llama输出是4096维度, 则开发者嵌入是其三倍大.  
   这应该不是大问题, 有问题无非加一层ANN. 希望只是杞人忧天. 


不过抛开项目本身, 导致现在进度慢的原因还有: 
1. 懒散. 5号才开始动手; 
2. 对工作量低估太多, 甚至认为一晚上就能做好; 
3. 弱鸡的代码能力. 


## 安排

今天是 5月5日. 

1. 实体信息获取: 可能还再需要一周时间.   
   三个实体中, Issue已经算是完成了, 只要运行即可;   
   接下来可能会尝试PR, 这大概需要1~2天时间:  
    - 找到并转换自然语言部分 (半天内); 
    - 代码部分的转换: 2天. 顺利的话不到一天就能解决.

   Repository部分 (5天): 
    - 确保原始数据存在并找到它 (半天, 提前做)
    - 搞明白这块儿代码是怎么组织的 (1天)
    - 转换自然语言部分: 1天, 纯写代码, 垃圾时间
    - 转换代码部分: 2天. 
    - 拼接起来: 半天

2. 哪些是关联的? 生成开发者的向量, 并训练一个下游任务模型:  
   保守估计, 大概2~3天能解决. 

3. 其他三部分实体: 如果上面问题都解决了, 那也就多训练3个任务. 保守一点3天. 

再加上可能出现的新问题, 总体大概需要2周时间. 这样看, 时间并不多. 抓紧吧. 

